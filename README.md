# 计算机考研院校可视化推荐系统 - 开发文档

## 1. 项目概述

本项目旨在为计算机专业考研学生提供一个集院校信息查询、可视化分析和个性化推荐于一体的 Web 应用。系统核心功能包括：

* **可视化大面板:** 动态展示全国计算机考研相关的宏观数据。主要包括：
  * **中间区域**: 可滚动的院校列表，展示 `院校名称`, `院校等级`, `省份`, `地区(A/B区)`, `计算机等级`。 (注: `24年招生人数` 和 `初试科目` 在此速览中暂不直接显示，详情页可见)
  * **左侧面板**:
    * 左上: 近三年计算机考研**总分国家线折线图**。
    * 左中: 近三年**政治国家线柱状图**。
    * 左下: 近三年**英语(一/二)与数学(一/二)国家线折线图**(4条)。
  * **右侧面板**:
    * 右上: 计算机考研**自命题 vs 408统考比例饼图**。
    * 右中/右下: **考研公告通知模块**(内容由后台管理)。
* **院校库查询:** 允许用户根据 `省份`, `地区(A/B区)`, `院校等级`, `院校名称`, `计算机等级` 等维度筛选院校，并按 `收藏人数` 或 `24年招生人数` 排序。查询结果以列表形式展示 `院校名称`, `院校等级`, `计算机等级`, `省份`, `地区(A/B区)`, `24年招生人数`, `收藏人数`。
* **院校详情:** 展示院校的详细信息，包括 `学校简介`, `招生院系架构`, `专业代码对照表`, `考试科目`, `招生人数`, `学费学制`, `地区(A/B区)`。特别地，对于已爬取数据的四川院校，会展示近三年的**复试线趋势图**。
* **个性化推荐:** 基于用户的个人情况（`目标分数`, `目标院校等级`, `目标院校计算机等级`, `目标地区(省份或A/B区)`）和加权评分算法，推荐最合适的 Top 20 院校。推荐算法如下：
  * **推荐评分** = \(0.35 \times \text{分数相似度} + 0.2 \times \text{院校等级分} + 0.15 \times \text{计算机等级分} + 0.2 \times \text{地区匹配分} + 0.1 \times \text{热度分}\)
  * **权重规则:**

        | 指标           | 权重 | 评分规则                                   |
        | -------------- | ---- | ------------------------------------------ |
        | 目标分数       | 35%  | 基于用户预期分数与院校历年分数线的误差计算     |
        | 院校等级       | 20%  | 985=100, 211=80, 双一流=60, 一般=30 (若与目标等级匹配则为100,否则按此基础分) |
        | 计算机等级     | 15%  | A+=100, A=90, ..., 无=20 (若与目标等级匹配则为设定值,否则按此基础分) |
        | 地区匹配 (省份/考区) | 20%  | 目标省份匹配=100, 目标考区匹配=50, 否则=0 |
        | 热度分 (收藏数)| 10%  | (收藏数 / 50) * 100, 最高100分              |
  * 输出结果列表展示 `院校名称`, `院校等级`, `计算机等级`, `省份`, `地区(A/B区)`, `推荐分数`。
* **交互功能**:
  * **院校收藏**: 用户可在院校列表或详情页点击心形图标 (空心 -> 实心) 收藏院校，收藏结果计入用户个人中心的收藏列表。
  * **页面跳转**: 支持从院校库、推荐结果列表点击进入院校详情页。
* **用户管理 (前后台):**
  * 支持用户注册、登录、登出。
  * 用户可查看和编辑个人资料（学历、专业、目标等）。
  * 用户可收藏/取消收藏感兴趣的院校。
  * 管理员可在后台查看用户列表、创建新用户（可设为管理员）、删除用户、查看用户详情、切换用户管理员状态。
* **后台管理:** 提供管理员界面，用于管理用户、公告信息。
  * **管理员认证**: 通过在用户 JSON 文件中手动设置 `is_admin: true` 实现。
  * **公告管理**: 管理员可添加、删除公告信息。
  * **管理员设置**: 管理员可修改自己的登录密码。
* **系统日志**: 将关键操作记录到 `logs/app.log` 文件。

本项目的一个关键特点是**不依赖传统数据库**，所有数据（院校信息、国家线、公告、用户信息、收藏夹）均以 **JSON 文件** 形式存储在服务器的文件系统中 (`data/` 目录)。后端逻辑使用 Python 和 Flask 框架实现。

**重要提示:** 基于文件的用户数据存储和密码哈希（`werkzeug.security`）相比明文有改进，但**仍不适合生产环境**，存在安全风险和性能瓶颈。

## 2. 技术栈

* **后端:**
  * **框架:** Flask
  * **数据处理:** Pandas (用于初始数据处理), JSON (用于运行时数据读写)
  * **密码处理:** Werkzeug
  * **日志:** Python `logging` 模块
  * **数据存储:** JSON 文件
  * **Web 服务器 (开发):** Flask 内建服务器
* **前端:**
  * **基础:** HTML, CSS, JavaScript
  * **可视化库:** ECharts
  * **UI 辅助:** Bootstrap 5 (部分页面), Font Awesome (图标)
* **开发工具:**
  * Python 3.x
  * pip (包管理)
  * Git (版本控制)

## 3. 项目结构

```text
computer_recommendation_system/
├── app.py             # Flask 后端主应用文件
├── data/              # 存放所有数据文件的文件夹
│   ├── schools.json     # 全国院校数据
│   ├── national_lines.json # 国家线数据
│   ├── announcements.json # 公告通知数据
│   ├── exam_type_ratios.json # 首页饼图"自命题vs408比例"数据
│   └── users/           # 存储用户信息的文件夹 (每个用户一个 JSON)
│       └── example_user.json
├── logs/              # 存放日志文件
│   └── app.log
├── static/            # 存放前端静态文件
│   ├── css/           # (style.css, navbar.css, forms.css)
│   └── js/            # (main.js)
├── templates/         # 存放 HTML 模板文件
│   ├── admin/           # 管理后台模板
│   │   ├── base_admin.html
│   │   ├── dashboard.html
│   │   ├── users.html
│   │   ├── user_detail.html
│   │   ├── announcements.html
│   │   ├── admin_profile.html
│   │   ├── edit_exam_ratios.html # 编辑饼图比例数据页面
│   │   └── edit_national_lines.html # 编辑国家线数据页面
│   ├── base.html        # 前台基础模板
│   ├── index.html       # 可视化大面板/首页
│   ├── school_list.html # 院校库查询结果页
│   ├── school_detail.html # 院校详情页
│   ├── recommendation.html # 推荐结果页
│   ├── login.html
│   ├── register.html
│   └── profile.html     # 用户个人中心
├── utils/             # 存放工具函数 (如 data_processor.py)
├── requirements.txt   # Python 依赖库
├── README.md          # 项目说明和开发文档
└── 择校文档.xlsx    # 原始数据文件 (示例)
```

## 4. 数据结构

核心数据存储在 `data/` 目录下的 JSON 文件中。

### `schools.json`

(结构同之前定义，包含 `id`, `name`, `level`, `province`, `region` (A区/B区), `intro`, `computer_rank`, `departments` [内含 `majors` {内含 `major_code`, `major_name`, `exam_subjects`, `reference_books`, `retrial_subjects`, `enrollment_24` (单个专业的招生人数), `tuition_duration`, `score_lines`, `admission_info_23`, `admission_info_24`}], `enrollment_24_school_total` (学校总招生人数), `favorites_count` (此字段在运行时计算，不存储在文件))。

### `national_lines.json`

存储各科国家线数据。

```json
{
  "total": { "years": [...], "scores": {"A区": [...], "B区": [...]}},
  "politics": { "years": [...], "scores": {"A区": [...], "B区": [...]}},
  "others": { "years": [...], "scores": {"英语一 (A区)": [...], ...}}
}
```

### `announcements.json`

存储公告信息列表。

```json
[
  {"title": "公告标题", "url": "公告链接 (可选)"},
  ...
]
```

### `data/exam_type_ratios.json`

存储首页"自命题 vs 408 比例"饼图的原始数据。

```json
[
  {"name": "自命题", "value": 150},
  {"name": "408统考", "value": 250}
]
```

### `data/users/username.json`

存储单个用户的信息。

```json
{
  "username": "string",        // 用户名 (与文件名一致)
  "password_hash": "string",   // Werkzeug 生成的密码哈希
  "is_admin": boolean,       // 是否为管理员 (默认为 false)
  "profile": {               // 用户个人资料和偏好
    "education_background": "string",
    "major_area": "string",
    "target_location": "string", // 省份
    "target_level": "string",    // 985, 211, etc.
    "expected_score": number | null
  },
  "favorites": ["string", ...] // 收藏的学校 ID (通常是学校名称) 列表
}
```

## 5. 已实现功能

* **核心展示**:
  * 可视化大面板
  * 院校库
  * 院校详情页
* **用户系统**: 注册、登录、登出、个人资料查看与修改、院校收藏与取消收藏。
* **推荐系统**: 基于用户偏好和加权算法的 Top 20 院校推荐。
* **管理后台**: 管理员登录、仪表盘、用户管理、公告管理、管理员密码修改、院校数据列表查看与顶层信息编辑。
* **日志记录**: 关键操作记录到 `logs/app.log` 文件。
* **数据爬取 (部分)**: 已实现针对 **四川大学** 和 **电子科技大学** 的专业目录和近三年分数线的爬取与合并逻辑 (`utils/scraper.py`)。
* **UI 风格**:
  * **固定为深色科技感主题**，并对全局样式和组件（Navbar, Card, Button, Form, Table, Accordion, Alert 等）进行了统一重构。

## 6. 运行说明

1. **安装依赖**: 确保已安装 Python 3.x 和 pip。在项目根目录下运行：

    ```bash
    pip install -r requirements.txt
    ```

2. **准备数据**: 确保 `data/schools.json`, `data/national_lines.json`, `data/announcements.json` 文件存在且格式正确。
3. **设置管理员**: 首次运行时，需要先注册一个用户，然后**手动修改**对应的 `data/users/用户名.json` 文件，在顶层添加 `"is_admin": true,`。
4. **运行应用**: 在项目根目录下运行：

    ```bash
    python app.py
    ```

5. **访问应用**: 打开浏览器访问 `http://127.0.0.1:5000/`。
6. **访问后台**: 使用管理员账户登录后，访问 `http://127.0.0.1:5000/admin/`。

## 7. 待办事项 (To-Do List)

* **[进行中]** **爬虫模块 (`utils/scraper.py`)**:
  * 已完成: 四川大学 (SCU), 电子科技大学 (UESTC) 数据抓取和解析。
  * **[待定]** **扩展爬取范围**: 添加对 `TARGET_SCHOOLS` 列表中其他学校（如西南交大、成都理工等）的特定解析逻辑和数据抓取。
  * **[待定]** **健壮性与容错**: 增强错误处理 (网络请求、解析错误、数据缺失)，添加更详细的日志记录。
  * **[待定]** **更新机制**: 实现增量更新或定期完全更新的策略。
  * **[待定]** **代理/延时**: 加入代理 IP 和请求延时，防止被封禁。
* **[进行中]** **前端页面 (`templates/`, `static/`)**:
  * **[已完成]** UI 风格固定为深色科技感主题，并进行了基础组件重构。
  * **[待完善]** 细节样式打磨（根据反馈继续调整）。
  * **[待完善]** 可视化大面板其余图表细节优化。
* **[待完成]** **后台功能**:
  * **[已部分实现]** 管理员可编辑首页图表数据（国家线、自命题/408比例）。(前端模板已创建，后端逻辑待实现)
  * **[待定]** 实现更精细的院校信息编辑（如院系、专业级别）。
  * **[待定]** 爬虫状态监控/管理界面。
* **(可选) 异步处理/后台任务**: 对于实际部署，考虑使用异步请求（如 `aiohttp`）或后台任务队列（如 Celery）来运行爬虫，避免阻塞 Web 应用主线程。

## 8. 爬虫模块 (`utils/scraper.py`)

本模块负责从指定高校的研究生招生网站爬取最新的招生信息，特别是针对四川省高校近三年的计算机相关专业数据，用以补充和更新核心数据文件 `data/schools.json`。

### 8.1 设计目标

* **目标院校**: 重点关注四川省内招收计算机相关专业研究生的高校。
* **目标专业**: 涵盖主流计算机相关专业代码，包括：
  * `081200` 计算机科学与技术 (学硕)
  * `083500` 软件工程 (学硕)
  * `083900` 网络空间安全 (学硕)
  * `085400` 电子信息 (专硕大类，具体方向需区分)
  * `085404` 计算机技术 (电子信息专硕方向)
  * `085405` 软件工程 (电子信息专硕方向)
  * `085410` 人工智能 (电子信息专硕方向)
  * `085411` 大数据技术与工程 (电子信息专硕方向)
* **目标数据维度 (近三年: 2022, 2023, 2024)**:
  * **招生人数**: 各专业（区分学硕/专硕、全日制/非全日制）的计划招生人数或实际录取人数。
  * **考试科目**: 初试科目代码和名称 (如 政治、英一/二、数一/二、408/自命题专业课)。
  * **复试分数线**: 各专业进入复试的总分线和单科线。
  * **参考书目**: 专业课初试和复试的推荐参考书。
  * **学费与学制**: 各专业的学费标准和基本学习年限。
  * **(可选)** 录取情况: 如最高分、最低分、平均分、拟录取名单公示链接等。
  * **(可选)** 招生简章/专业目录: 链接或关键文本内容。
* **数据更新**: 将爬取到的新数据**合并**到 `data/schools.json` 中对应的学校和专业条目下，而不是完全覆盖，以保留历史信息或其他手动维护的数据。

### 8.2 工作流程

1. **加载现有数据**: 启动时，`load_existing_schools()` 函数读取 `data/schools.json` 文件，将学校列表加载到内存中。
2. **遍历目标高校**: 脚本遍历 `TARGET_UNIVERSITIES` 字典中定义的四川省目标高校及其招生网基础 URL。
3. **解析单个学校 (`parse_school_data`)**: 对每个学校：
    * 使用 `fetch_page()` 获取学校招生主页的 HTML 内容。
    * 使用 `BeautifulSoup` 解析主页，尝试查找指向"硕士招生"、"专业目录"、"分数线"、"招生简章"等关键页面的链接。
    * 根据找到的链接，递归或迭代地 `fetch_page()` 获取更详细页面的 HTML 内容。
    * **核心解析逻辑**: 针对具体页面的 HTML 结构 (通常是表格 `<table>` 或列表 `<ul>`/`<ol>`)，编写精确的 `BeautifulSoup` 选择器 (`find()`, `find_all()`, CSS 选择器等) 来提取目标数据维度信息。
    * **数据结构化**: 将提取到的信息整理成符合 `schools.json` 中单个学校内部 `departments` 和 `majors` 结构的字典。
    * 处理可能出现的异常（如网络请求失败、页面结构变化、数据格式不规范等）。
4. **合并数据 (`update_school_data`)**: 将 `parse_school_data` 返回的单个学校的更新数据，与内存中加载的现有学校列表进行合并：
    * 根据学校名称找到 `schools_list` 中的对应学校条目。
    * **核心合并逻辑**: 遍历更新数据中的院系和专业，在现有数据中查找匹配项（通过院系名和专业代码）。
    * 对于找到的匹配项，**选择性地更新**字段。例如，更新 `score_lines` 字典中特定年份的分数，更新 `enrollment_24` 字段等，而不是替换整个 `majors` 字典。
    * 如果现有数据中不存在某个专业，可以选择添加该新专业。
5. **保存数据**: `run_scraper()` 函数在遍历完所有目标高校后，如果至少有一个学校的数据被成功更新，则调用 `save_schools_data()` 将内存中**完整且已合并**的学校列表写回到 `data/schools.json` 文件。
6. **延时**: 在处理完一个学校后，强制 `time.sleep()` 短暂延时，避免对目标网站造成过大压力。

### 8.3 待实现与关键点

* **URL 核实与填充**: 需要仔细查找并验证 `TARGET_UNIVERSITIES` 中每个学校的**准确**研究生招生信息入口 URL。
* **`parse_school_data` 的定制化**: 这是**最核心和工作量最大**的部分。需要为每个（或每类相似网站结构的）学校编写具体的 HTML 解析逻辑。需要大量使用浏览器开发者工具进行分析。
* **`update_school_data` 的精细化**: 实现健壮的数据合并逻辑至关重要，以避免覆盖有用信息。需要仔细设计如何根据年份、专业代码等更新特定字段。
* **目标专业代码的精确匹配**: 在解析专业目录时，需要确保只提取在 `8.1 设计目标` 中列出的专业代码相关信息。
* **近三年数据提取**: 解析分数线、招生人数等信息时，要特别注意识别和提取 **2022、2023、2024** 这三个年份的数据。
* **异常处理**: 增强网络请求、HTML 解析、数据合并等环节的异常处理能力。
* **(可选) 异步处理/后台任务**: 对于实际部署，考虑使用异步请求（如 `aiohttp`）或后台任务队列（如 Celery）来运行爬虫，避免阻塞 Web 应用主线程。

## 9. 运行与基本部署

1. **环境设置**: 确保已安装 Python 3.x 和 pip。建议使用虚拟环境：

    ```bash
    python -m venv .venv         # 创建虚拟环境 （目前已经创建）
    source .venv/bin/activate   # 激活虚拟环境 (Linux/macOS)
    # .venv\Scripts\activate      # 激活虚拟环境 (Windows)
    ```

2. **安装依赖**: 在激活虚拟环境后，安装所需库：

    ```bash
    pip install -r requirements.txt
    ```

3. **准备数据**: 确保 `
