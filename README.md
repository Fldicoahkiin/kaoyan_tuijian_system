# 计算机考研院校可视化推荐系统 - 开发文档

## 1. 项目概述

本项目旨在为计算机专业考研学生提供一个集院校信息查询、可视化分析和个性化推荐于一体的 Web 应用。系统核心功能包括：

* **可视化大面板:** 动态展示全国计算机考研相关的宏观数据，如国家线趋势、院校分布、考试类型比例等。前端使用 ECharts 绘制图表。
* **院校库查询:** 允许用户根据地区、院校层次、计算机学科评估等级、院校名称等多维度筛选院校，并按收藏热度排序。
* **院校详情:** 展示院校的详细信息，包括简介、院系专业、招生人数、复试线（暂无图表）、参考书目等。
* **个性化推荐:** 基于用户的个人情况（预期分数、目标地区、院校偏好等）和加权评分算法，推荐合适的院校（取 Top 20）。
* **用户管理 (前后台):**
  * 支持用户注册、登录、登出。
  * 用户可查看和编辑个人资料（学历、专业、目标等）。
  * 用户可收藏/取消收藏感兴趣的院校。
  * 管理员可在后台查看用户列表、创建新用户（可设为管理员）、删除用户、查看用户详情、切换用户管理员状态。
* **后台管理:** 提供管理员界面，用于管理用户、公告信息。
  * **管理员认证**: 通过在用户 JSON 文件中手动设置 `is_admin: true` 实现。
  * **公告管理**: 管理员可添加、删除公告信息。
  * **管理员设置**: 管理员可修改自己的登录密码。
* **系统日志**: 将关键操作记录到 `logs/app.log` 文件。

本项目的一个关键特点是**不依赖传统数据库**，所有数据（院校信息、国家线、公告、用户信息、收藏夹）均以 **JSON 文件** 形式存储在服务器的文件系统中 (`data/` 目录)。后端逻辑使用 Python 和 Flask 框架实现。

**重要提示:** 基于文件的用户数据存储和密码哈希（`werkzeug.security`）相比明文有改进，但**仍不适合生产环境**，存在安全风险和性能瓶颈。

## 2. 技术栈

* **后端:**
  * **框架:** Flask
  * **数据处理:** Pandas (用于初始数据处理), JSON (用于运行时数据读写)
  * **密码处理:** Werkzeug
  * **日志:** Python `logging` 模块
  * **数据存储:** JSON 文件
  * **Web 服务器 (开发):** Flask 内建服务器
* **前端:**
  * **基础:** HTML, CSS, JavaScript
  * **可视化库:** ECharts
  * **UI 辅助:** Bootstrap 5 (部分页面), Font Awesome (图标)
* **开发工具:**
  * Python 3.x
  * pip (包管理)
  * Git (版本控制)

## 3. 项目结构

```text
computer_recommendation_system/
├── app.py             # Flask 后端主应用文件
├── data/              # 存放所有数据文件的文件夹
│   ├── schools.json     # 全国院校数据
│   ├── national_lines.json # 国家线数据
│   ├── announcements.json # 公告通知数据
│   └── users/           # 存储用户信息的文件夹 (每个用户一个 JSON)
│       └── example_user.json
├── logs/              # 存放日志文件
│   └── app.log
├── static/            # 存放前端静态文件
│   ├── css/           # (style.css, navbar.css, forms.css)
│   └── js/            # (main.js)
├── templates/         # 存放 HTML 模板文件
│   ├── admin/           # 管理后台模板
│   │   ├── base_admin.html
│   │   ├── dashboard.html
│   │   ├── users.html
│   │   ├── user_detail.html
│   │   ├── announcements.html
│   │   └── admin_profile.html
│   ├── base.html        # 前台基础模板
│   ├── index.html       # 可视化大面板/首页
│   ├── school_list.html # 院校库查询结果页
│   ├── school_detail.html # 院校详情页
│   ├── recommendation.html # 推荐结果页
│   ├── login.html
│   ├── register.html
│   └── profile.html     # 用户个人中心
├── utils/             # 存放工具函数 (如 data_processor.py)
├── requirements.txt   # Python 依赖库
├── README.md          # 项目说明和开发文档
└── 择校文档.xlsx    # 原始数据文件 (示例)
```

## 4. 数据结构

核心数据存储在 `data/` 目录下的 JSON 文件中。

### `schools.json`

(结构同之前定义，包含 `id`, `name`, `level`, `region`, `province`, `intro`, `computer_rank`, `self_vs_408`, `departments` [内含 `majors` {内含 `major_code`, `major_name`, `exam_subjects`, `reference_books`, `retrial_subjects`, `enrollment_24`, `tuition_duration`, `score_lines`, `admission_info_23`, `admission_info_24`}], `favorites_count` (此字段在运行时计算，不存储在文件))。

### `national_lines.json`

存储各科国家线数据。

```json
{
  "total": { "years": [...], "scores": {"A区": [...], "B区": [...]}},
  "politics": { "years": [...], "scores": {"A区": [...], "B区": [...]}},
  "others": { "years": [...], "scores": {"英语一 (A区)": [...], ...}}
}
```

### `announcements.json`

存储公告信息列表。

```json
[
  {"title": "公告标题", "url": "公告链接 (可选)"},
  ...
]
```

### `data/users/username.json`

存储单个用户的信息。

```json
{
  "username": "string",        // 用户名 (与文件名一致)
  "password_hash": "string",   // Werkzeug 生成的密码哈希
  "is_admin": boolean,       // 是否为管理员 (默认为 false)
  "profile": {               // 用户个人资料和偏好
    "education_background": "string",
    "major_area": "string",
    "target_location": "string", // 省份
    "target_level": "string",    // 985, 211, etc.
    "expected_score": number | null
  },
  "favorites": ["string", ...] // 收藏的学校 ID (通常是学校名称) 列表
}
```

## 5. 已实现功能

* **核心展示**: 可视化面板（各类图表、院校滚动列表）、院校库（查询、排序）、院校详情页（初步实现四川院校近三年分数线图表）。
* **用户系统**: 注册、登录、登出、个人资料查看与修改、院校收藏与取消收藏。
* **推荐系统**: 基于用户偏好和加权算法的 Top 20 院校推荐。
* **管理后台**: 管理员登录、仪表盘、用户管理（列表、创建、删除、详情、切换管理员）、公告管理（列表、添加、删除）、管理员密码修改、**院校数据列表查看**。
* **日志记录**: 关键操作记录到 `logs/app.log` 文件。

## 6. 运行说明

1. **安装依赖**: 确保已安装 Python 3.x 和 pip。在项目根目录下运行：

    ```bash
    pip install -r requirements.txt
    ```

2. **准备数据**: 确保 `data/schools.json`, `data/national_lines.json`, `data/announcements.json` 文件存在且格式正确。
3. **设置管理员**: 首次运行时，需要先注册一个用户，然后**手动修改**对应的 `data/users/用户名.json` 文件，在顶层添加 `"is_admin": true,`。
4. **运行应用**: 在项目根目录下运行：

    ```bash
    python app.py
    ```

5. **访问应用**: 打开浏览器访问 `http://127.0.0.1:5000/`。
6. **访问后台**: 使用管理员账户登录后，访问 `http://127.0.0.1:5000/admin/`。

## 7. 待办与未来方向 (示例)

* **院校数据管理**: 实现后台**完整**更新/管理 `schools.json` 的功能（可能通过上传文件或集成爬虫）。
* **爬虫功能**: 实现 `utils/scraper.py` 用于爬取四川院校近三年数据或其他院校的最新信息。
* **分数线图表**: 进一步完善院校详情页四川院校分数线图表的稳定性和数据覆盖。
* **推荐算法优化**: 使用更精确的数据（如平均录取分）优化分数相似度计算。
* **分页**: 为院校库和推荐结果添加分页功能 (院校库分页已完成)。
* **UI/UX 改进**: 优化页面布局和用户体验。
* **安全性增强**: 替换文件存储为数据库，使用更安全的认证机制。
* **后台系统管理**: 实现轮播图配置等。

## 8. 爬虫模块 (`utils/scraper.py`)

本模块负责从指定高校的研究生招生网站爬取最新的招生信息，特别是针对四川省高校近三年的计算机相关专业数据，用以补充和更新核心数据文件 `data/schools.json`。

### 8.1 设计目标

* **目标院校**: 重点关注四川省内招收计算机相关专业研究生的高校。
* **目标专业**: 涵盖主流计算机相关专业代码，包括：
  * `081200` 计算机科学与技术 (学硕)
  * `083500` 软件工程 (学硕)
  * `083900` 网络空间安全 (学硕)
  * `085400` 电子信息 (专硕大类，具体方向需区分)
  * `085404` 计算机技术 (电子信息专硕方向)
  * `085405` 软件工程 (电子信息专硕方向)
  * `085410` 人工智能 (电子信息专硕方向)
  * `085411` 大数据技术与工程 (电子信息专硕方向)
* **目标数据维度 (近三年: 2022, 2023, 2024)**:
  * **招生人数**: 各专业（区分学硕/专硕、全日制/非全日制）的计划招生人数或实际录取人数。
  * **考试科目**: 初试科目代码和名称 (如 政治、英一/二、数一/二、408/自命题专业课)。
  * **复试分数线**: 各专业进入复试的总分线和单科线。
  * **参考书目**: 专业课初试和复试的推荐参考书。
  * **学费与学制**: 各专业的学费标准和基本学习年限。
  * **(可选)** 录取情况: 如最高分、最低分、平均分、拟录取名单公示链接等。
  * **(可选)** 招生简章/专业目录: 链接或关键文本内容。
* **数据更新**: 将爬取到的新数据**合并**到 `data/schools.json` 中对应的学校和专业条目下，而不是完全覆盖，以保留历史信息或其他手动维护的数据。

### 8.2 工作流程

1. **加载现有数据**: 启动时，`load_existing_schools()` 函数读取 `data/schools.json` 文件，将学校列表加载到内存中。
2. **遍历目标高校**: 脚本遍历 `TARGET_UNIVERSITIES` 字典中定义的四川省目标高校及其招生网基础 URL。
3. **解析单个学校 (`parse_school_data`)**: 对每个学校：
    * 使用 `fetch_page()` 获取学校招生主页的 HTML 内容。
    * 使用 `BeautifulSoup` 解析主页，尝试查找指向"硕士招生"、"专业目录"、"分数线"、"招生简章"等关键页面的链接。
    * 根据找到的链接，递归或迭代地 `fetch_page()` 获取更详细页面的 HTML 内容。
    * **核心解析逻辑**: 针对具体页面的 HTML 结构 (通常是表格 `<table>` 或列表 `<ul>`/`<ol>`)，编写精确的 `BeautifulSoup` 选择器 (`find()`, `find_all()`, CSS 选择器等) 来提取目标数据维度信息。
    * **数据结构化**: 将提取到的信息整理成符合 `schools.json` 中单个学校内部 `departments` 和 `majors` 结构的字典。
    * 处理可能出现的异常（如网络请求失败、页面结构变化、数据格式不规范等）。
4. **合并数据 (`update_school_data`)**: 将 `parse_school_data` 返回的单个学校的更新数据，与内存中加载的现有学校列表进行合并：
    * 根据学校名称找到 `schools_list` 中的对应学校条目。
    * **核心合并逻辑**: 遍历更新数据中的院系和专业，在现有数据中查找匹配项（通过院系名和专业代码）。
    * 对于找到的匹配项，**选择性地更新**字段。例如，更新 `score_lines` 字典中特定年份的分数，更新 `enrollment_24` 字段等，而不是替换整个 `majors` 字典。
    * 如果现有数据中不存在某个专业，可以选择添加该新专业。
5. **保存数据**: `run_scraper()` 函数在遍历完所有目标高校后，如果至少有一个学校的数据被成功更新，则调用 `save_schools_data()` 将内存中**完整且已合并**的学校列表写回到 `data/schools.json` 文件。
6. **延时**: 在处理完一个学校后，强制 `time.sleep()` 短暂延时，避免对目标网站造成过大压力。

### 8.3 待实现与关键点

* **URL 核实与填充**: 需要仔细查找并验证 `TARGET_UNIVERSITIES` 中每个学校的**准确**研究生招生信息入口 URL。
* **`parse_school_data` 的定制化**: 这是**最核心和工作量最大**的部分。需要为每个（或每类相似网站结构的）学校编写具体的 HTML 解析逻辑。需要大量使用浏览器开发者工具进行分析。
* **`update_school_data` 的精细化**: 实现健壮的数据合并逻辑至关重要，以避免覆盖有用信息。需要仔细设计如何根据年份、专业代码等更新特定字段。
* **目标专业代码的精确匹配**: 在解析专业目录时，需要确保只提取在 `8.1 设计目标` 中列出的专业代码相关信息。
* **近三年数据提取**: 解析分数线、招生人数等信息时，要特别注意识别和提取 **2022、2023、2024** 这三个年份的数据。
* **异常处理**: 增强网络请求、HTML 解析、数据合并等环节的异常处理能力。
* **(可选) 异步处理/后台任务**: 对于实际部署，考虑使用异步请求（如 `aiohttp`）或后台任务队列（如 Celery）来运行爬虫，避免阻塞 Web 应用主线程。
